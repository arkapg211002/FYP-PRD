% -------------------- Result and Analysis ----------------------------------



\section{Results and Analysis}
%Prepare the test plans in tabular format, where each Test Case should be represented with distinct id, prefixed with “$\langle$module$\rangle$ “, where module represents the short code of the respective design module. Test Case numbers should be matching as stated in Requirement Matrix.
%\vspace{.1in}

%\noindent

%Appropriate definition of ‘Performance Metrics’, e.g. Classification Accuracy, Mean Squared Error etc. should be included, as applicable. 
%\vspace{.1in}

%\noindent
%Depending on your specific project, test results can be represented as a table of data with a corresponding pie chart / bar chart as needed. Analysis of test results should be discussed in terms of clear bullet points.

\noindent
The metrics used for evaluating the performance of the classification models include Precision, Recall, F1-Score, and Support, along with the Confusion Matrix. These metrics are crucial for assessing how well the models are able to differentiate between various classes, providing insight into their accuracy, ability to capture relevant instances, and the overall balance between precision and recall. By analyzing these metrics, a comprehensive understanding of the model's performance can be obtained, enabling informed decisions for further optimization and tuning.

\subsection{Classification Metrics and Confusion Matrix}

\begin{itemize}
    \item \textbf{Precision:} Precision is the ratio of correctly predicted positive observations to the total predicted positives. It can be calculated as:
    \[
    \text{Precision} = \frac{TP}{TP + FP}
    \]
    where \( TP \) represents True Positives, and \( FP \) represents False Positives.

    \item \textbf{Recall:} Recall is the ratio of correctly predicted positive observations to all observations in the actual class:
    \[
    \text{Recall} = \frac{TP}{TP + FN}
    \]
    where \( TP \) is True Positives, and \( FN \) is False Negatives.

    \item \textbf{F1-Score:} F1-Score is the harmonic mean of Precision and Recall, calculated as:
    \[
    \text{F1-Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
    \]

    \item \textbf{Support:} Support refers to the number of actual occurrences of each class in the dataset:
    \[
    \text{Support} = \text{Number of samples in the true class}
    \]

    \item \textbf{Confusion Matrix:} A confusion matrix is used to evaluate the performance of a classification model. It is structured as follows:
    \[
    \begin{bmatrix}
    TP & FP \\
    FN & TN
    \end{bmatrix}
    \]
    where:
    \begin{itemize}
        \item \( TP \) = True Positives
        \item \( FP \) = False Positives
        \item \( FN \) = False Negatives
        \item \( TN \) = True Negatives
    \end{itemize}
\end{itemize}

\subsection{Results of Logistic Regression}

\begin{center}
    \textbf{Logistic Regression Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety        & 0.83               & 0.77            & 0.80              & 379              \\ \hline
        Bipolar        & 0.74               & 0.55            & 0.63              & 384              \\ \hline
        Depression     & 0.76               & 0.76            & 0.76              & 373              \\ \hline
        Normal         & 0.92               & 0.99            & 0.95              & 2183             \\ \hline
        PTSD           & 0.87               & 0.77            & 0.82              & 394              \\ \hline
        \textbf{Accuracy} & \multicolumn{4}{|c|}{87.66\%} \\ \hline
        \textbf{Macro Avg} & 0.82            & 0.77            & 0.79              & 3713             \\ \hline
        \textbf{Weighted Avg} & 0.87         & 0.88            & 0.87              & 3713             \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{Confusion Matrix for Logistic Regression Model} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Anxiety} & \textbf{Bipolar} & \textbf{Depression} & \textbf{Normal} & \textbf{PTSD} \\ \hline
        \textbf{Anxiety}    & 291 & 18  & 27  & 24  & 19  \\ \hline
        \textbf{Bipolar}    & 7   & 213 & 29  & 125 & 10  \\ \hline
        \textbf{Depression} & 26  & 31  & 283 & 18  & 15  \\ \hline
        \textbf{Normal}     & 3   & 10  & 4   & 2165 & 1   \\ \hline
        \textbf{PTSD}       & 24  & 16  & 29  & 22  & 303 \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.95            \\ \hline
        Bipolar         & 0.92            \\ \hline
        Depression      & 0.96            \\ \hline
        Normal          & 0.99            \\ \hline
        PTSD            & 0.95            \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\noindent
The Logistic Regression model performed well with an overall accuracy of 87.66\%, indicating that the model correctly classified the majority of the instances. The classification report shows high precision, recall, and F1-scores for the 'Normal' class, which was expected due to its large number of instances. However, the 'Bipolar' and 'Anxiety' classes have lower recall and F1-scores, suggesting that the model struggles more with these classes. The confusion matrix highlights the misclassifications. For example, 'Anxiety' is often confused with 'Depression' and 'PTSD,' while the 'Normal' class is well-separated from the other classes. The large number of instances in the 'Normal' class could have contributed to the high accuracy but also to the imbalance in performance across other classes. The ROC curve AUC scores indicate that the model performs well in distinguishing between the classes. The 'Normal' class has the highest AUC (0.99), which is expected due to the large proportion of 'Normal' instances. Other classes, like 'Anxiety' and 'Depression,' also have high AUC scores (0.95 and 0.96, respectively), indicating that the model is capable of distinguishing them effectively.


\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.9\textwidth]{Images/LR Confusion Matrix.png}  
    \caption{Confusion Matrix (Logistic Regression)}
    \label{LRCM}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.9\textwidth]{Images/LR ROC.png}  
    \caption{ROC AUC (Logistic Regression)}
    \label{LRROC}  % Label for referencing the figure
\end{figure}

\pagebreak

\subsection{Results of Naive Bayes}

\begin{center}
    \textbf{Naive Bayes Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety        & 0.70               & 0.73            & 0.72              & 379              \\ \hline
        Bipolar        & 0.83               & 0.45            & 0.58              & 384              \\ \hline
        Depression     & 0.59               & 0.87            & 0.70              & 373              \\ \hline
        Normal         & 0.96               & 0.92            & 0.94              & 2183             \\ \hline
        PTSD           & 0.71               & 0.83            & 0.76              & 394              \\ \hline
        \textbf{Accuracy} & \multicolumn{4}{|c|}{83.63\%} \\ \hline
        \textbf{Macro Avg} & 0.76            & 0.76            & 0.74              & 3713             \\ \hline
        \textbf{Weighted Avg} & 0.85         & 0.84            & 0.84              & 3713             \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{Confusion Matrix for Naive Bayes Model} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Anxiety} & \textbf{Bipolar} & \textbf{Depression} & \textbf{Normal} & \textbf{PTSD} \\ \hline
        \textbf{Anxiety}    & 278 & 4    & 63  & 3    & 31    \\ \hline
        \textbf{Bipolar}    & 30  & 171  & 62  & 86   & 35    \\ \hline
        \textbf{Depression} & 26  & 6    & 323 & 0    & 18    \\ \hline
        \textbf{Normal}     & 38  & 21   & 68  & 2006 & 50    \\ \hline
        \textbf{PTSD}       & 24  & 5    & 34  & 4    & 327   \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.92            \\ \hline
        Bipolar         & 0.89            \\ \hline
        Depression      & 0.94            \\ \hline
        Normal          & 0.99            \\ \hline
        PTSD            & 0.94            \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.8\textwidth]{Images/NB Confusion Matrix.png}  
    \caption{Confusion Matrix (Naive Bayes)}
    \label{NBCM}  % Label for referencing the figure
\end{figure}

\noindent
The Naive Bayes model achieved an overall accuracy of 83.63\%, indicating a reasonable performance. The classification report shows strong results for the Normal class, with a precision of 0.96 and a recall of 0.92, resulting in an F1-score of 0.94. However, the Bipolar class exhibits much lower recall (0.45) and F1-score (0.58), suggesting that the model struggles to accurately identify Bipolar instances. Misclassifications are more frequent for Bipolar, often being confused with Depression and PTSD. The Anxiety class, although having decent precision (0.70), shows a lower recall (0.73), indicating that it also faces challenges in classification. The Confusion Matrix highlights that the model has difficulty distinguishing Bipolar and Depression from each other, with a large number of misclassifications across these classes. On the other hand, the Normal class is well-separated and correctly classified, with 2006 true positives, which likely contributes to the high overall accuracy. PTSD also shows relatively good classification results, with misclassifications being less frequent. The ROC AUC Curve Areas show that the model performs well for most classes, with the Normal class having the highest AUC score (0.99), followed by Depression and PTSD with AUCs of 0.94. While the model performs well for distinguishing between classes like Normal and Depression, the lower AUC for Bipolar (0.89) indicates that there may still be room for improvement in distinguishing this class from others.



\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.75\textwidth]{Images/NB ROC.png}  
    \caption{ROC AUC (Naive Bayes)}
    \label{NBROC}  % Label for referencing the figure
\end{figure}


\subsection{Results of Support Vector Machine}

\begin{center}
    \textbf{SVM Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety        & 0.72               & 0.76            & 0.74              & 379              \\ \hline
        Bipolar        & 0.62               & 0.61            & 0.61              & 384              \\ \hline
        Depression     & 0.74               & 0.71            & 0.72              & 373              \\ \hline
        Normal         & 0.94               & 0.95            & 0.95              & 2183             \\ \hline
        PTSD           & 0.78               & 0.74            & 0.76              & 394              \\ \hline
        \textbf{Accuracy} & \multicolumn{4}{|c|}{85.13\%} \\ \hline
        \textbf{Macro Avg} & 0.76            & 0.75            & 0.76              & 3713             \\ \hline
        \textbf{Weighted Avg} & 0.85         & 0.85            & 0.85              & 3713             \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{Confusion Matrix for SVM Model} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Anxiety} & \textbf{Bipolar} & \textbf{Depression} & \textbf{Normal} & \textbf{PTSD} \\ \hline
        \textbf{Anxiety}    & 287 & 22  & 29  & 13  & 28  \\ \hline
        \textbf{Bipolar}    & 20  & 233 & 29  & 88  & 14  \\ \hline
        \textbf{Depression} & 37  & 31  & 265 & 11  & 29  \\ \hline
        \textbf{Normal}     & 20  & 62  & 8   & 2084 & 9  \\ \hline
        \textbf{PTSD}       & 34  & 26  & 29  & 13  & 292 \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.96            \\ \hline
        Bipolar         & 0.90            \\ \hline
        Depression      & 0.96            \\ \hline
        Normal          & 0.98            \\ \hline
        PTSD            & 0.96            \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.8\textwidth]{Images/SVM Confusion Matrix.png}  
    \caption{Confusion Matrix (SVM)}
    \label{SVMCM}  % Label for referencing the figure
\end{figure}

\noindent
The Support Vector Machine (SVM) model achieved an accuracy of 85.13\%, demonstrating strong performance in classifying the various mental health conditions. The classification report indicates that the Normal class has the highest precision (0.94) and recall (0.95), resulting in an F1-score of 0.95, showing that the model is particularly good at identifying instances of normal behavior. However, the Bipolar class shows lower performance, with a precision of 0.62 and recall of 0.61, suggesting that the model struggles more with identifying bipolar disorder instances. The recall for the Anxiety class is relatively high (0.76), though precision is somewhat lower (0.72), indicating a balanced classification performance for this condition. The confusion matrix reveals that the model is generally accurate, with the Normal class being correctly classified most of the time (2084 true positives). However, some misclassifications occur for classes like Bipolar, Depression, and PTSD, with notable misclassifications of Bipolar as Depression and Normal. These misclassifications are likely affecting the overall recall for certain classes. The ROC AUC curve areas demonstrate that the model has excellent performance in distinguishing between most classes. The Normal class has the highest AUC of 0.98, followed by Anxiety, Depression, and PTSD with AUCs of 0.96. Bipolar, although still high at 0.90, lags behind the other classes, reflecting the model's challenge in distinguishing Bipolar from other conditions.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.75\textwidth]{Images/SVM ROC.png}  
    \caption{ROC AUC (SVM)}
    \label{SVMSOC}  % Label for referencing the figure
\end{figure}


\subsection{Results of Random Forest}

\begin{center}
    \textbf{Random Forest Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety        & 0.81               & 0.70            & 0.75              & 379              \\ \hline
        Bipolar        & 0.93               & 0.47            & 0.62              & 384              \\ \hline
        Depression     & 0.72               & 0.77            & 0.74              & 373              \\ \hline
        Normal         & 0.88               & 1.00            & 0.93              & 2183             \\ \hline
        PTSD           & 0.92               & 0.74            & 0.82              & 394              \\ \hline
        \textbf{Accuracy} & \multicolumn{4}{|c|}{86.00\%} \\ \hline
        \textbf{Macro Avg} & 0.85            & 0.73            & 0.77              & 3713             \\ \hline
        \textbf{Weighted Avg} & 0.86         & 0.86            & 0.85              & 3713             \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{Confusion Matrix for Random Forest Model} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Anxiety} & \textbf{Bipolar} & \textbf{Depression} & \textbf{Normal} & \textbf{PTSD} \\ \hline
        \textbf{Anxiety}    & 264 & 3   & 34  & 68  & 10  \\ \hline
        \textbf{Bipolar}    & 12  & 180 & 46  & 141 & 5   \\ \hline
        \textbf{Depression} & 26  & 3   & 286 & 48  & 10  \\ \hline
        \textbf{Normal}     & 3   & 6   & 1   & 2173 & 0  \\ \hline
        \textbf{PTSD}       & 19  & 2   & 30  & 53  & 290 \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.96            \\ \hline
        Bipolar         & 0.89            \\ \hline
        Depression      & 0.97            \\ \hline
        Normal          & 0.97            \\ \hline
        PTSD            & 0.97            \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.8\textwidth]{Images/RF Confusion Matrix.png}  
    \caption{Confusion Matrix (Random Forest)}
    \label{RFCM}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.7\textwidth]{Images/RF ROC.png}  
    \caption{ROC AUC (Random Forest)}
    \label{RFROC}  % Label for referencing the figure
\end{figure}

\noindent
The Random Forest model achieved an accuracy of 86.00\%, indicating a strong performance in classifying the mental health conditions. The classification report shows that the Normal class achieved the highest recall (1.00) and a precision of 0.88, resulting in a high F1-score of 0.93. This reflects the model’s ability to correctly classify the majority of the Normal instances. The Bipolar class, however, shows a much lower recall (0.47), which indicates that the model has difficulty identifying instances of Bipolar disorder, as reflected by its F1-score of 0.62. The Anxiety and PTSD classes have relatively balanced performance, with moderate precision and recall values. The confusion matrix illustrates the distribution of misclassifications. The Normal class is correctly classified almost entirely (2173 true positives), while other classes like Bipolar and PTSD exhibit significant misclassifications, particularly Bipolar, which is often misclassified as Depression and Normal. The ROC AUC scores for all classes are quite high, indicating that the model is effective at distinguishing between the classes. The Anxiety, Depression, Normal, and PTSD classes each have AUC values above 0.96, with the Normal and Depression classes achieving 0.97. Bipolar has the lowest AUC at 0.89, which corresponds to its lower classification performance. These AUC values suggest that the Random Forest model is proficient in distinguishing between most of the classes, though it faces challenges in identifying Bipolar disorder.




\subsection{Results of XGBoost}

\begin{center}
    \textbf{XGBoost Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety        & 0.81               & 0.74            & 0.77              & 403              \\ \hline
        Bipolar        & 0.77               & 0.62            & 0.69              & 397              \\ \hline
        Depression     & 0.72               & 0.81            & 0.76              & 387              \\ \hline
        Normal         & 0.93               & 0.98            & 0.95              & 2137             \\ \hline
        PTSD           & 0.86               & 0.75            & 0.80              & 396              \\ \hline
        \textbf{Accuracy} & \multicolumn{4}{|c|}{87.39\%} \\ \hline
        \textbf{Macro Avg} & 0.82            & 0.78            & 0.80              & 3720             \\ \hline
        \textbf{Weighted Avg} & 0.87         & 0.87            & 0.87              & 3720             \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{Confusion Matrix for XGBoost Model} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Anxiety} & \textbf{Bipolar} & \textbf{Depression} & \textbf{Normal} & \textbf{PTSD} \\ \hline
        \textbf{Anxiety}    & 297 & 20  & 39  & 24  & 23  \\ \hline
        \textbf{Bipolar}    & 13  & 248 & 36  & 92  & 8   \\ \hline
        \textbf{Depression} & 30  & 13  & 313 & 17  & 14  \\ \hline
        \textbf{Normal}     & 3   & 28  & 8   & 2096 & 2   \\ \hline
        \textbf{PTSD}       & 22  & 12  & 36  & 29  & 297 \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.97            \\ \hline
        Bipolar         & 0.95            \\ \hline
        Depression      & 0.97            \\ \hline
        Normal          & 0.99            \\ \hline
        PTSD            & 0.97            \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\noindent
The XGBoost model achieved an accuracy of 87.39\%, demonstrating strong overall performance. The classification report indicates high precision and recall for the 'Normal' class, which is likely due to its substantial representation in the dataset. The 'Anxiety' and 'PTSD' classes also showed reasonable results, with the 'Anxiety' class achieving a precision of 0.81 and a recall of 0.74. However, the 'Bipolar' class exhibited a lower recall (0.62), suggesting that the model struggles more with this class. The confusion matrix highlights a well-separated 'Normal' class, while the 'Bipolar' and 'PTSD' classes experience more confusion with other categories. The ROC AUC scores further emphasize the model's good discriminatory capability, with AUC values of 0.97 for 'Anxiety,' 'Depression,' and 'PTSD,' and 0.99 for 'Normal.' These scores indicate that the model is proficient at distinguishing between different mental health conditions in the dataset.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.85\textwidth]{Images/XG Confusion Matrix.png}  
    \caption{Confusion Matrix (XGBoost)}
    \label{XGCM}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.85\textwidth]{Images/XG ROC.png}  
    \caption{ROC AUC (XGBoost)}
    \label{XGrOC}  % Label for referencing the figure
\end{figure}


\subsection{Results of KNN}

\begin{center}
    \textbf{KNN Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety        & 0.58               & 0.31            & 0.40              & 379              \\ \hline
        Bipolar        & 0.18               & 0.59            & 0.28              & 384              \\ \hline
        Depression     & 0.47               & 0.39            & 0.43              & 373              \\ \hline
        Normal         & 0.79               & 0.69            & 0.73              & 2183             \\ \hline
        PTSD           & 0.80               & 0.09            & 0.16              & 394              \\ \hline
        \textbf{Accuracy} & \multicolumn{4}{|c|}{54.46\%} \\ \hline
        \textbf{Macro Avg} & 0.56            & 0.41            & 0.40              & 3713             \\ \hline
        \textbf{Weighted Avg} & 0.67         & 0.54            & 0.56              & 3713             \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{Confusion Matrix for KNN Model} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Anxiety} & \textbf{Bipolar} & \textbf{Depression} & \textbf{Normal} & \textbf{PTSD} \\ \hline
        \textbf{Anxiety}    & 117 & 122 & 35  & 101 & 4   \\ \hline
        \textbf{Bipolar}    & 7   & 226 & 40  & 108 & 3   \\ \hline
        \textbf{Depression} & 24  & 129 & 145 & 74  & 1   \\ \hline
        \textbf{Normal}     & 11  & 657 & 15  & 1499 & 1  \\ \hline
        \textbf{PTSD}       & 41  & 120 & 74  & 124 & 35  \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.73            \\ \hline
        Bipolar         & 0.67            \\ \hline
        Depression      & 0.77            \\ \hline
        Normal          & 0.80            \\ \hline
        PTSD            & 0.67            \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\noindent
The KNN model achieved an accuracy of 54.46\%, which is considerably lower than the XGBoost model. The classification report reveals a significant imbalance in performance across classes. The 'Normal' class achieved relatively high precision (0.79) and recall (0.69), reflecting the model's tendency to perform well with dominant classes. However, the 'Anxiety' and 'PTSD' classes performed poorly, especially with PTSD having a very low recall of 0.09, indicating substantial misclassification. The confusion matrix suggests that the model struggles with distinguishing between some classes, especially 'Anxiety' and 'Bipolar,' where confusion with other categories is high. The ROC AUC scores are relatively lower compared to the XGBoost model, with 'Normal' having the highest AUC of 0.80. These results indicate that while the KNN model offers a lower overall performance, it still provides a reasonable level of discrimination for the 'Normal' class.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.85\textwidth]{Images/KNN Confusion Matrix.png}  
    \caption{Confusion Matrix (KNN)}
    \label{KNNCM}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.85\textwidth]{Images/KNN ROC.png}  
    \caption{ROC AUC (KNN)}
    \label{KNnROC}  % Label for referencing the figure
\end{figure}



\subsection{Results of LSTM}

\begin{center}
    \textbf{LSTM Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety        & 0.81               & 0.68            & 0.74              & 403              \\ \hline
        Bipolar        & 0.60               & 0.59            & 0.60              & 397              \\ \hline
        Depression     & 0.56               & 0.77            & 0.65              & 387              \\ \hline
        Normal         & 0.96               & 0.96            & 0.96              & 2137             \\ \hline
        PTSD           & 0.76               & 0.61            & 0.68              & 396              \\ \hline
        \textbf{Accuracy} & \multicolumn{4}{|c|}{83.55\%} \\ \hline
        \textbf{Macro Avg} & 0.74            & 0.72            & 0.73              & 3720             \\ \hline
        \textbf{Weighted Avg} & 0.84         & 0.84            & 0.84              & 3720             \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{Confusion Matrix for LSTM Model} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Anxiety} & \textbf{Bipolar} & \textbf{Depression} & \textbf{Normal} & \textbf{PTSD} \\ \hline
        \textbf{Anxiety}    & 274 & 36  & 32  & 28  & 33  \\ \hline
        \textbf{Bipolar}    & 26  & 233 & 42  & 85  & 11  \\ \hline
        \textbf{Depression} & 25  & 31  & 299 & 19  & 13  \\ \hline
        \textbf{Normal}     & 6   & 18  & 11  & 2043 & 9   \\ \hline
        \textbf{PTSD}       & 31  & 33  & 33  & 35  & 264 \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.95            \\ \hline
        Bipolar         & 0.92            \\ \hline
        Depression      & 0.94            \\ \hline
        Normal          & 0.99            \\ \hline
        PTSD            & 0.95            \\ \hline
    \end{tabular}
\end{center}

\vspace{0.25em}

\noindent
The LSTM model achieved an accuracy of 83.55\%, indicating strong performance, although it lags slightly behind other models such as XGBoost and SVM. The classification report shows high precision, recall, and F1-scores for the 'Normal' class, which dominates the dataset. The 'Anxiety' class has reasonable performance, with a precision of 0.81 and recall of 0.68, but the 'Bipolar' and 'PTSD' classes have lower precision and recall, especially for 'Bipolar' (0.60 in both precision and recall). The confusion matrix reflects this, with 'Bipolar' and 'PTSD' misclassified with other classes, while 'Normal' is well-separated. The ROC AUC scores highlight the model's ability to distinguish between classes effectively, with 'Normal' scoring the highest AUC of 0.99, followed by other classes such as 'Anxiety' and 'Depression,' both with AUCs above 0.90.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.85\textwidth]{Images/LSTM Confusion Matrix.png}  
    \caption{Confusion Matrix (LSTM)}
    \label{LSTMCM}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.8\textwidth]{Images/LSTM ROC.png}  
    \caption{ROC AUC (LSTM)}
    \label{LSTMROC}  % Label for referencing the figure
\end{figure}

\pagebreak
\noindent
Among the various machine learning algorithms tested, Logistic Regression emerged as the best performing model. With an accuracy of 87.66\%, it outperformed the other models in terms of overall accuracy, precision, recall, and F1-score. The classification report for Logistic Regression shows strong performance across all classes, especially the 'Normal' class, which had high precision (0.92) and recall (0.99). Although the model faced challenges with the 'Bipolar' class, which had lower recall and F1-score, its overall ability to differentiate between other mental health conditions was impressive. The confusion matrix and ROC AUC scores further highlight the model’s robustness, with an AUC of 0.99 for the 'Normal' class and strong values for other classes as well. This indicates that Logistic Regression not only achieves high accuracy but also performs well in distinguishing between different mental health categories, making it the most reliable choice for this classification task.


\subsection{Results of Hyperparameter Tuning}

\begin{center}
    \textbf{Hyperparameter Tuning on Logistic Regression} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Best Hyperparameters}  & \textbf{Value} \\ \hline
        Solver                        & liblinear      \\ \hline
        Penalty                       & l2             \\ \hline
        C                              & 1              \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class}  & \textbf{Precision}  & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety         & 0.83                & 0.77            & 0.80              & 379             \\ \hline
        Bipolar         & 0.74                & 0.55            & 0.64              & 384             \\ \hline
        Depression      & 0.76                & 0.76            & 0.76              & 373             \\ \hline
        Normal          & 0.92                & 0.99            & 0.95              & 2183            \\ \hline
        PTSD            & 0.87                & 0.77            & 0.82              & 394             \\ \hline
        Accuracy        & 0.88                &                 &                   & 3713            \\ \hline
        Macro avg       & 0.83                & 0.77            & 0.79              & 3713            \\ \hline
        Weighted avg    & 0.87                & 0.88            & 0.87              & 3713            \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.95            \\ \hline
        Bipolar         & 0.92            \\ \hline
        Depression      & 0.96            \\ \hline
        Normal          & 0.99            \\ \hline
        PTSD            & 0.95            \\ \hline
    \end{tabular}
\end{center}

\noindent
The results of hyperparameter tuning on the Logistic Regression model show that the best hyperparameters were a solver of \texttt{liblinear}, a penalty of \texttt{l2}, and a regularization parameter (\texttt{C}) of 1. The model achieved an overall accuracy of 87.72\%, with high performance across most classes. The classification report reveals that the model performs well on \texttt{normal} class with an accuracy of 92\% in predicting this class, whereas performance on \texttt{bipolar} is slightly lower \(64\% F1-score\). The ROC AUC scores indicate that the model is highly effective in distinguishing between different classes, with \texttt{normal} achieving a near-perfect AUC of 0.99, followed closely by \texttt{depression} at 0.96. These results suggest that the model is well-tuned, particularly for classes like \texttt{normal} and \texttt{anxiety}.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.7\textwidth]{Images/HP LR CM.png}  
    \caption{Classification Matrix after Hyperparameter Tuning (Logistic Regression)}
    \label{LSTMROC2}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.7\textwidth]{Images/HP LR ROC.png}  
    \caption{ROC AUC after Hyperparamter Tuning (Logistic Regression)}
    \label{LSTMROC3}  % Label for referencing the figure
\end{figure}



\begin{center}
    \textbf{Hyperparameter Tuning on k-NN} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Best Hyperparameters}  & \textbf{Value} \\ \hline
        Weights                       & distance       \\ \hline
        n\_neighbors                  & 10             \\ \hline
        Metric                        & euclidean      \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class}  & \textbf{Precision}  & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety         & 0.73                & 0.23            & 0.35              & 379             \\ \hline
        Bipolar         & 0.18                & 0.60            & 0.27              & 384             \\ \hline
        Depression      & 0.47                & 0.40            & 0.43              & 373             \\ \hline
        Normal          & 0.74                & 0.65            & 0.69              & 2183            \\ \hline
        PTSD            & 0.83                & 0.10            & 0.18              & 394             \\ \hline
        Accuracy        & 0.52                &                 &                   & 3713            \\ \hline
        Macro avg       & 0.59                & 0.40            & 0.39              & 3713            \\ \hline
        Weighted avg    & 0.66                & 0.52            & 0.53              & 3713            \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.77            \\ \hline
        Bipolar         & 0.67            \\ \hline
        Depression      & 0.79            \\ \hline
        Normal          & 0.79            \\ \hline
        PTSD            & 0.71            \\ \hline
    \end{tabular}
\end{center}

\noindent
The results of hyperparameter tuning on the k-Nearest Neighbors (k-NN) model show that the best hyperparameters were \texttt{weights} set to \texttt{distance}, \texttt{n\_neighbors} set to 10, and \texttt{metric} set to \texttt{euclidean}. Despite these optimizations, the model achieved an overall accuracy of 52.03\%, which is relatively low. The classification report indicates that the model struggled to effectively predict the \texttt{anxiety} and \texttt{PTSD} classes, with particularly low recall values (0.23 and 0.10, respectively). However, it performed reasonably well on the \texttt{normal} class with an F1-score of 0.69. The ROC AUC scores reflect this by showing relatively poor performance for \texttt{bipolar} (0.67) and \texttt{PTSD} (0.71), while \texttt{normal} and \texttt{depression} had slightly better values at 0.79 each. These results suggest that k-NN is not the best model for this dataset, as it fails to consistently classify the minority classes effectively. 


\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.9\textwidth]{Images/HP KNN CM.png}  
    \caption{Classification Matrix after Hyperparameter Tuning (KNN)}
    \label{LSTMROC4}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.9\textwidth]{Images/HP KNN ROC.png}  
    \caption{ROC AUC after Hyperparameter Tuning (KNN)}
    \label{LSTMROC5}  % Label for referencing the figure
\end{figure}

\pagebreak

\begin{center}
    \textbf{Hyperparameter Tuning on SVM} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Best Hyperparameters}  & \textbf{Value} \\ \hline
        Kernel                        & linear         \\ \hline
        Gamma                         & scale          \\ \hline
        C                              & 1              \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class}  & \textbf{Precision}  & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety         & 0.72                & 0.76            & 0.74              & 379             \\ \hline
        Bipolar         & 0.62                & 0.61            & 0.61              & 384             \\ \hline
        Depression      & 0.74                & 0.71            & 0.72              & 373             \\ \hline
        Normal          & 0.94                & 0.95            & 0.95              & 2183            \\ \hline
        PTSD            & 0.78                & 0.74            & 0.76              & 394             \\ \hline
        Accuracy        & 0.85                &                 &                   & 3713            \\ \hline
        Macro avg       & 0.76                & 0.75            & 0.76              & 3713            \\ \hline
        Weighted avg    & 0.85                & 0.85            & 0.85              & 3713            \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.92            \\ \hline
        Bipolar         & 0.88            \\ \hline
        Depression      & 0.95            \\ \hline
        Normal          & 0.98            \\ \hline
        PTSD            & 0.94            \\ \hline
    \end{tabular}
\end{center}

\noindent
The results of hyperparameter tuning on the Support Vector Machine (SVM) model reveal that the best hyperparameters were \texttt{kernel} set to \texttt{linear}, \texttt{gamma} set to \texttt{scale}, and \texttt{C} set to 1. With these settings, the model achieved an overall accuracy of 85.13\%. The classification report indicates solid performance across most classes, with \texttt{normal} achieving the highest F1-score of 0.95, followed by \texttt{depression} at 0.72 and \texttt{anxiety} at 0.74. The \texttt{bipolar} class had a slightly lower F1-score of 0.61, indicating that the model was less effective in distinguishing this class. The ROC AUC values were strong for most classes, with \texttt{normal} reaching 0.98 and \texttt{depression}, \texttt{PTSD}, and \texttt{anxiety} all scoring above 0.90, showing that the SVM model effectively discriminates between the classes. Overall, the SVM model performed well on this dataset, particularly for the \texttt{normal} and \texttt{anxiety} classes, making it a strong contender for mental health issue classification.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.85\textwidth]{Images/HP SVM CM.png}  
    \caption{Classification Matrix after Hyperparameter Tuning (SVM)}
    \label{LSTMROC6}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.9\textwidth]{Images/HP SVM ROC.png}  
    \caption{ROC AUC after Hyperparameter Tuning (SVM)}
    \label{LSTMROC}  % Label for referencing the figure
\end{figure}


\pagebreak

\begin{center}
    \textbf{Hyperparameter Tuning on Naive Bayes} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Best Hyperparameters}  & \textbf{Value} \\ \hline
        Alpha                         & 0.2914180608409973 \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{Classification Report} \\[0.5em]
    \begin{tabular}{|l|c|c|c|c|}
        \hline
        \textbf{Class}  & \textbf{Precision}  & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        Anxiety         & 0.69                & 0.76            & 0.72              & 379             \\ \hline
        Bipolar         & 0.75                & 0.55            & 0.64              & 384             \\ \hline
        Depression      & 0.60                & 0.83            & 0.70              & 373             \\ \hline
        Normal          & 0.96                & 0.91            & 0.94              & 2183            \\ \hline
        PTSD            & 0.73                & 0.79            & 0.76              & 394             \\ \hline
        Accuracy        & 0.84                &                 &                   & 3713            \\ \hline
        Macro avg       & 0.75                & 0.77            & 0.75              & 3713            \\ \hline
        Weighted avg    & 0.85                & 0.84            & 0.84              & 3713            \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{ROC Curve Areas for Each Class} \\[0.5em]
    \begin{tabular}{|l|c|}
        \hline
        \textbf{Class}  & \textbf{ROC AUC} \\ \hline
        Anxiety         & 0.93            \\ \hline
        Bipolar         & 0.93            \\ \hline
        Depression      & 0.93            \\ \hline
        Normal          & 0.99            \\ \hline
        PTSD            & 0.94            \\ \hline
    \end{tabular}
\end{center}

\noindent
The results of hyperparameter tuning on the Naive Bayes model show that the best hyperparameter was \texttt{alpha} set to 0.2914. With this optimal value, the model achieved an accuracy of 83.95\%. The classification report reveals that the \texttt{normal} class performed the best, with a high F1-score of 0.94, followed by \texttt{PTSD} at 0.76. The \texttt{anxiety} class achieved a solid F1-score of 0.72, while \texttt{bipolar} and \texttt{depression} had lower scores. The ROC AUC curve areas demonstrate strong performance across all classes, with \texttt{normal} reaching a perfect 0.99 and the other classes scoring above 0.90. Overall, the Naive Bayes model performed well, especially in identifying \texttt{normal} and \texttt{PTSD}, making it a good candidate for mental health issue classification.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.85\textwidth]{Images/HP NB CM.png}  
    \caption{Classification Matrix after Hyperparameter Tuning (Naive Bayes)}
    \label{LSTMROC7}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.9\textwidth]{Images/HP NB ROC.png}  
    \caption{ROC AUC after Hyperparameter Tuning (Naive Bayes)}
    \label{LSTMROC8}  % Label for referencing the figure
\end{figure}

\pagebreak

\noindent
After performing hyperparameter tuning using RandomizedSearchCV, Logistic Regression emerged as the best-performing model for mental health classification. The model achieved an accuracy of 87.72\%, demonstrating its strong ability to correctly classify mental health issues based on text data. The best hyperparameters found during tuning were \texttt{'solver': 'liblinear', 'penalty': 'l2', 'C': 1}, which contributed to the model's robustness and efficiency. In terms of classification performance, Logistic Regression showed a high recall and precision, especially for classes like \textit{normal}, with a recall of 0.99, indicating its proficiency in identifying the most prevalent class in the dataset. Furthermore, the ROC AUC scores for each class were impressive, with values close to or exceeding 0.90, which suggests excellent model discrimination between classes. Overall, Logistic Regression's combination of high accuracy, solid precision-recall balance, and optimal hyperparameters makes it the most suitable model for this task.


\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/ML GRAPH 1.png}  
    \caption{Result Comparison of the Algorithms}
    \label{dfdl145}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/ML GRAPH 2 HT.png}  
    \caption{Result Comparison after Hyperparameter Tuning}
    \label{dfdl123}  % Label for referencing the figure
\end{figure}


\noindent 
K-Nearest Neighbors (KNN) performs significantly poorly on this dataset compared to other algorithms, both before and after hyperparameter tuning. The dataset used, which includes Reddit posts with corresponding mental health labels, presents challenges for KNN due to its reliance on distance-based metrics. Specifically, KNN uses the distance between data points to classify them, but this approach is sensitive to the scale and distribution of features. In the case of text data, the feature space can be sparse and high-dimensional, making it difficult for KNN to find meaningful relationships between the posts and their associated mental health labels. After hyperparameter tuning, KNN was optimized with parameters such as \textbf{weights='distance'}, \textbf{n\_neighbors=10}, and \textbf{metric='euclidean'}, yet its performance remains suboptimal. This suggests that KNN struggles with the complexities inherent in text classification tasks, where the relationships between features (such as words or phrases in a Reddit post) are often non-linear and context-dependent. Despite tuning, the algorithm's performance metrics—accuracy, precision, recall, and F1-score—remain notably lower than those of other algorithms like Logistic Regression, Naive Bayes, or SVM. Additionally, KNN's inability to capture these subtleties in language means it performs poorly, particularly in distinguishing between categories like anxiety, bipolar disorder, or PTSD, where the text patterns may be more nuanced. Overall, KNN's reliance on proximity without considering the richer context of textual data likely contributes to its lower performance on this mental health classification task. Other algorithms, particularly those that are more suited for high-dimensional and sparse data (like Logistic Regression or SVM), show much better results as they can better account for the underlying patterns in the Reddit posts.

\pagebreak

\subsection{Results from Ensemble Model Training and Testing}
\subsubsection{Logistic Regression and XGBoost}
\begin{center}
    \textbf{Classification Report for Ensemble Model} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        \textbf{Anxiety}    & 0.96 & 0.93 & 0.95 & 1999 \\ \hline
        \textbf{Bipolar}    & 0.90 & 0.86 & 0.88 & 1941 \\ \hline
        \textbf{Depression} & 0.95 & 0.94 & 0.94 & 1959 \\ \hline
        \textbf{Normal}     & 0.97 & 0.99 & 0.98 & 10679 \\ \hline
        \textbf{PTSD}       & 0.98 & 0.95 & 0.96 & 1987 \\ \hline
        \textbf{Accuracy}   & \multicolumn{4}{c|}{\textbf{96.09\%}} \\ \hline
        \textbf{Macro avg}  & 0.95 & 0.93 & 0.94 & 18565 \\ \hline
        \textbf{Weighted avg} & 0.96 & 0.96 & 0.96 & 18565 \\ \hline
    \end{tabular}
\end{center}

\begin{center}
    \textbf{ROC AUC Scores for Each Class} \\[0.5em]
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Class} & \textbf{ROC AUC} \\ \hline
        Anxiety  & 1.0 \\ \hline
        Bipolar  & 0.99 \\ \hline
        Depression & 0.99 \\ \hline
        Normal   & 1.0 \\ \hline
        PTSD     & 1.0 \\ \hline
    \end{tabular}
\end{center}

\noindent
The classification report provides an insightful summary of the ensemble model's performance, which combines Logistic Regression and XGBoost to classify mental health issues. Precision is a key metric that measures the proportion of correctly predicted positive cases out of all the positive predictions made by the model. For example, a precision of 0.96 for anxiety means that when the model predicts anxiety, it is correct 96\% of the time. Recall, on the other hand, reflects the model's ability to identify all actual positive cases in the dataset. A recall of 0.93 for anxiety suggests that the model correctly identifies 93\% of all true anxiety cases. The F1-score, which balances precision and recall, is also an important metric. With an F1-score of 0.95 for anxiety, the model strikes a good balance between precision and recall, indicating that it performs well across both metrics. Support represents the number of actual instances of a class in the dataset, and for anxiety, there are 1999 instances in the test set. The model's overall accuracy is 96.09\%, meaning that it correctly predicts the mental health condition for 96.09\% of the test instances, reflecting the overall effectiveness of the model. The macro average, which takes the unweighted mean of precision, recall, and F1-scores across all classes, shows an average precision of 0.95, recall of 0.93, and F1-score of 0.94. This provides a general idea of the model's performance across all classes without accounting for class imbalance. The weighted average, however, adjusts for the class distribution by giving more weight to classes with more instances. The weighted averages for precision, recall, and F1-score are all 0.96, reflecting strong overall performance, especially when considering the differing class sizes. The ROC AUC scores are another key performance indicator that evaluates the model's ability 

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/EM CM.png}  
    \caption{Confusion Matrix for Ensemble Model(LR + XGB)}
    \label{dfdl3123}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/EM ROC.png}  
    \caption{ROC AUC Curve for Ensemble Model(LR + XGB)}
    \label{dfdl12443}  % Label for referencing the figure
\end{figure}

\noindent
to distinguish between different classes. The AUC score ranges from 0 to 1, with 1 representing perfect classification. A perfect AUC score of 1.0 for anxiety, normal, and PTSD indicates that the model can perfectly differentiate between these classes and others. The AUC scores for bipolar and depression are 0.99, which is almost perfect, further demonstrating the model's strong performance across all classes. Overall, these metrics indicate that the ensemble model is highly effective at classifying mental health issues, with robust precision, recall, and the ability to distinguish between the different conditions. The confusion matrix will provide insight into the number of false positives, false negatives, true positives, and true negatives for each class. By looking at the confusion matrix, you can better understand where the model might be misclassifying certain classes, such as when it confuses anxiety with depression or bipolar with PTSD. For example, a high number of false positives in the anxiety class would mean the model is often predicting anxiety when it's actually a different mental health condition. Conversely, a high number of false negatives would mean the model is missing anxiety cases. The combination of logistic regression and XGBoost allows the ensemble model to leverage the strengths of both algorithms. While logistic regression is simple and interpretable, it might struggle with non-linearities in the data. XGBoost, on the other hand, is a powerful gradient boosting algorithm that can capture complex patterns in the data. By stacking their predictions, the ensemble model benefits from both simplicity and complexity, achieving higher accuracy and robustness in text-based classification tasks.

\vspace{1em}

\noindent
This ensemble model, combining Logistic Regression and XGBoost, is highly effective for the mental health classification web application due to its ability to leverage the strengths of both algorithms. Logistic Regression provides a simple yet powerful linear approach to classification, offering interpretability and efficiency, while XGBoost excels at handling complex, non-linear relationships with its gradient boosting framework, enabling better accuracy and robustness. By stacking these models, the ensemble approach mitigates the individual weaknesses of each algorithm—Logistic Regression's limitations in capturing non-linear patterns and XGBoost's susceptibility to overfitting on small datasets—resulting in a more balanced, accurate, and generalizable model. This synergy ensures that the mental health classification web application delivers reliable, high-precision predictions across diverse text-based inputs.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/EM RESULT.png}  
    \caption{Comparison of results from LR, XGB and Ensemble Model}
    \label{dfdl1244883}  % Label for referencing the figure
\end{figure}

\subsubsection{Logistic Regression, SVM, Naive Bayes, XGBoost(meta-learner), LSTM}

\begin{center}
    \textbf{Classification Report} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|c|}
        \hline
        & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        \textbf{Anxiety}    & 1.00 & 1.00 & 1.00 & 1999 \\ \hline
        \textbf{Bipolar}    & 1.00 & 1.00 & 1.00 & 1941 \\ \hline
        \textbf{Depression} & 1.00 & 1.00 & 1.00 & 1959 \\ \hline
        \textbf{Normal}     & 1.00 & 1.00 & 1.00 & 10679 \\ \hline
        \textbf{PTSD}       & 1.00 & 1.00 & 1.00 & 1987 \\ \hline
        \textbf{Accuracy}   & \multicolumn{4}{c|}{\textbf{99.59\%}} \\ \hline
        \textbf{Macro avg}  & 1.00 & 1.00 & 1.00 & 18565 \\ \hline
        \textbf{Weighted avg} & 1.00 & 1.00 & 1.00 & 18565 \\ \hline
    \end{tabular}
\end{center}

\pagebreak
\begin{center}
    \textbf{ROC AUC Scores for Each Class} \\[0.5em]
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Class} & \textbf{ROC AUC} \\ \hline
        Anxiety  & 1.0 \\ \hline
        Bipolar  & 1.0 \\ \hline
        Depression & 1.0 \\ \hline
        Normal   & 1.0 \\ \hline
        PTSD     & 1.0 \\ \hline
    \end{tabular}
\end{center}

\noindent
Each row of the matrix represents the true class, while each column represents the predicted class. The diagonal elements (1997, 1936, 1959, 10671, 1987) show the number of correct predictions for each class (anxiety, bipolar, depression, normal, PTSD), while the off-diagonal elements represent misclassifications. For example, the model misclassified 2 samples from the anxiety class as depression and 1 sample from the bipolar class as normal, but overall, the model made very few misclassifications. An ROC AUC score of 1.0 indicates perfect classification performance for each class, meaning that the model has perfectly separated the classes based on the probability predictions. This reinforces the outstanding performance of the XGBoost model.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=0.9\textwidth]{Images/EM4 CM.png}  
    \caption{Confusion Matrix for ensemble model (XGB - meta learner)}
    \label{dfdl1244883}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/EM4 ROC.png}  
    \caption{ROC AUC Curve for multiple models in ensemble model (XGB - meta learner)}
    \label{dfdl1244883}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/EM4 RESULT.png}  
    \caption{Comparison of results with Ensemble Model (XGB - meta learner)}
    \label{dfdl1244883}  % Label for referencing the figure
\end{figure}


\noindent
Using XGBoost as a meta-learner in an ensemble model is a strategic decision that brings several advantages, both in terms of performance and interpretability. To understand why XGBoost is an excellent choice, it is important to first appreciate the concept of a meta-learner and how ensemble learning works. Ensemble learning involves combining multiple base models to improve prediction accuracy by leveraging their individual strengths. In a typical ensemble method, the predictions of several base models (e.g., logistic regression, SVM, Naive Bayes, LSTM) are used as input features for a meta-learner, which then learns how to best combine these predictions to make a final decision. The meta-learner's role is to determine which base model's predictions are more reliable for each sample, thus improving the overall performance of the ensemble. XGBoost, a gradient boosting algorithm, has several features that make it an ideal candidate for a meta-learner in this context. First, XGBoost is known for its ability to handle complex relationships in data, especially in terms of interactions between features. Unlike simpler models like logistic regression or Naive Bayes, XGBoost builds decision trees iteratively, where each new tree is focused on correcting the errors made by the previous trees. This iterative approach allows XGBoost to capture non-linear patterns and subtle interactions that might be missed by individual base models. When used as a meta-learner, XGBoost can intelligently combine the predictions from the base models by learning the optimal way to weigh the output of each base model. This is especially important in a multi-model setting where different classifiers might have complementary strengths—XGBoost can effectively "learn" when to trust each model's prediction more, depending on the characteristics of the input data. Another advantage of using XGBoost as a meta-learner is its regularization capabilities. XGBoost includes both L1 and L2 regularization, which helps prevent overfitting. In the context of ensemble learning, this is particularly useful because, with multiple models contributing to the final prediction, the meta-learner needs to ensure it doesn't overly rely on any one base model, especially if that model is prone to overfitting. By applying regularization, XGBoost encourages the model to generalize well, ensuring that the ensemble is robust and does not become overly sensitive to the training data or to noise.

\vspace{1em}
\noindent
Additionally, XGBoost is highly efficient in terms of both computation and memory usage. It is designed to work well with large datasets, and its ability to handle sparse data effectively makes it a good fit for a wide variety of tasks, including those involving textual data or other high-dimensional inputs. In ensemble models, where multiple base models generate a large number of features (e.g., prediction probabilities from each base model), XGBoost’s efficiency in processing these features allows it to scale well even as the number of base models or the size of the dataset grows. Another key benefit is XGBoost’s ability to handle imbalanced datasets. Many classification tasks, especially in medical or mental health data, suffer from class imbalances, where some classes (e.g., “Normal”) are more frequent than others (e.g., “Bipolar” or “PTSD”). XGBoost has built-in features to adjust for class imbalances, such as using class weights or employing custom loss functions. This is important in a meta-learner context because the base models might not be equally effective across all classes. XGBoost can ensure that the ensemble model doesn't bias its predictions toward the majority class, which is crucial for improving the overall classification performance, especially for underrepresented classes.  Furthermore, XGBoost provides excellent interpretability through feature importance scores. In an ensemble model, where several base models contribute to the final prediction, understanding how each base model influences the outcome is valuable for both improving the model and for explaining its behavior. XGBoost offers built-in tools to analyze the importance of individual features (in this case, the predictions of the base models), allowing practitioners to understand how the meta-learner is making decisions and which base models are contributing the most to its predictions. Lastly, XGBoost’s performance in various machine learning competitions has demonstrated its robustness. It is one of the top-performing algorithms in tasks such as classification and regression, often outperforming other methods, including random forests and neural networks. Its popularity and track record make it a safe and reliable choice for a meta-learner.


\vspace{1em}

\noindent
While using models like XGBoost, SVM, Naive Bayes, and LSTM as meta-learners in ensemble modeling can provide high accuracy, these models can also be prone to \textbf{overfitting}, especially when they are trained on the predictions of multiple base models. Overfitting occurs when the model learns the noise or patterns specific to the training data that do not generalize well to unseen data. For XGBoost, although it is a powerful and highly flexible model, its ability to capture complex relationships between features can lead to overfitting, especially when the base models are already strong. When combined with a large number of features from multiple base models, the XGBoost meta-learner may excessively adjust to small fluctuations in the training data, leading to high performance on the training set but poor generalization to new data. This risk is heightened if the base models already provide overlapping or correlated predictions, which can reinforce irrelevant patterns for the meta-learner.

\vspace{1em}

\noindent
Similarly, SVM as a meta-learner can overfit in ensemble setups. SVM, especially when using a non-linear kernel, is very sensitive to the scale of features and may become highly specialized to the training data if not properly tuned. When stacking the output of multiple base models, each with its own biases and prediction tendencies, the SVM meta-learner may overemphasize specific instances that are not representative of the general data distribution. This can lead to poor performance on new, unseen data despite strong accuracy on the training set.

\vspace{1em}

\noindent
Naive Bayes is another model that can overfit when used as a meta-learner. Although it assumes independence between features, stacking it with predictions from base models may violate this assumption, leading to overly optimistic performance during training. Naive Bayes models are particularly sensitive to correlated features, and in an ensemble, where the base models might produce similar predictions, the meta-learner might end up fitting to these correlations too closely. This results in high training accuracy but a significant drop in performance when applied to unseen data.

\vspace{1em}

\noindent
Finally, LSTM models, although excellent at capturing long-range dependencies in sequential data, can also overfit when used as a meta-learner. LSTMs are prone to memorizing the training data, especially when the number of parameters in the model is large relative to the size of the training set. In ensemble settings, the LSTM meta-learner might overly adapt to the specific features of the training data, particularly when the base models' predictions are very similar, reinforcing the same patterns in the data. This can cause the LSTM meta-learner to perform well on training data but fail to generalize effectively to new data.

\vspace{1em}

\noindent
In conclusion, while these models can provide high accuracy in ensemble setups, they are also susceptible to overfitting, which can undermine their ability to generalize to new, unseen data. Proper regularization, cross-validation, and tuning of hyperparameters are necessary to mitigate these risks and improve the model's robustness and generalization capabilities.


\subsubsection{Logistic Regression(meta-learner), SVM, Naive Bayes, XGBoost, LSTM}

\begin{center}
    \textbf{Cross-Validation Accuracy Scores} \\[0.5em]
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Cross-Validation Accuracy Scores} & \textbf{Value} \\ \hline
        1 & 0.97333692 \\ \hline
        2 & 0.96768112 \\ \hline
        3 & 0.97091301 \\ \hline
        4 & 0.96606518 \\ \hline
        5 & 0.97037436 \\ \hline
        \textbf{Mean Cross-Validation Accuracy} & \textbf{96.97\%} \\ \hline
    \end{tabular}
\end{center}

\pagebreak

\begin{center}
    \textbf{Classification Report} \\[0.5em]
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} & \textbf{Support} \\ \hline
        \textbf{Anxiety}    & 0.96 & 0.95 & 0.95 & 1999 \\ \hline
        \textbf{Bipolar}    & 0.93 & 0.90 & 0.92 & 1941 \\ \hline
        \textbf{Depression} & 0.95 & 0.95 & 0.95 & 1959 \\ \hline
        \textbf{Normal}     & 0.98 & 0.99 & 0.99 & 10679 \\ \hline
        \textbf{PTSD}       & 0.97 & 0.96 & 0.96 & 1987 \\ \hline
        \textbf{Accuracy}   & \multicolumn{4}{c|}{97.05\%} \\ \hline
        \textbf{Macro avg}  & 0.96 & 0.95 & 0.95 & 18565 \\ \hline
        \textbf{Weighted avg} & 0.97 & 0.97 & 0.97 & 18565 \\ \hline
    \end{tabular}
\end{center}

\vspace{1em}

\begin{center}
    \textbf{ROC AUC Scores} \\[0.5em]
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Anxiety} & 1.00 \\ \hline
        \textbf{Bipolar} & 0.99 \\ \hline
        \textbf{Depression} & 1.00 \\ \hline
        \textbf{Normal} & 1.00 \\ \hline
        \textbf{PTSD} & 1.00 \\ \hline
    \end{tabular}
\end{center}

\noindent
The confusion matrix for the Logistic Regression model shows the performance of the classifier for each of the five mental health issues. For anxiety, 1900 true positives, 24 false positives, 33 false negatives, and 18 true negatives were recorded. This means the model was very accurate in detecting anxiety with minimal errors. Similarly, the bipolar disorder class had 1754 true positives and relatively few misclassifications, indicating high precision and recall. Depression also had a high number of correct predictions with 1857 true positives. The normal class had 10608 true positives and only minor misclassifications, highlighting the model's ability to classify the majority class accurately. The PTSD class showed similar performance with 1899 true positives. Overall, the confusion matrix suggests that the Logistic Regression model is highly effective in correctly classifying mental health conditions with very few errors across all classes. The ROC AUC scores for each class are all exceptionally high, with the anxiety, depression, normal, and PTSD classes achieving a perfect score of 1.00. The bipolar class has a slightly lower but still impressive score of 0.99. These high ROC AUC values indicate that the model is able to distinguish between the different classes with very high accuracy and minimal overlap between the predicted and actual values, ensuring robust model performance.

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/EM FINAL CM.png}  
    \caption{Confusion Matrix for Ensemble Model (LR - meta learner)}
    \label{dfdl1244883}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/EM FINAL ROC.png}  
    \caption{ROC AUC for Ensemble Model (LR - meta learner)}
    \label{dfdl1244883}  % Label for referencing the figure
\end{figure}

\begin{figure}[h!]  
    \centering
    \includegraphics[width=1.0\textwidth]{Images/EM FINAL RESULT.png}  
    \caption{Comparison of results with Ensemble Model (LR - meta learner)}
    \label{dfdl1244883}  % Label for referencing the figure
\end{figure}

\pagebreak

\noindent
Logistic Regression is also highly effective at combining probabilistic outputs from base models. Since ensemble methods often rely on predictions in the form of probabilities, Logistic Regression is able to leverage these to produce more accurate final predictions. It can weigh the predictions from each base model appropriately, allowing the ensemble to take advantage of the strengths of each model. This ability to combine probabilities is critical when base models have different levels of confidence in their predictions.

\vspace{1em}

\noindent
Additionally, Logistic Regression is computationally efficient, making it a great choice for large ensembles. Training and inference times for Logistic Regression are relatively fast compared to more complex models like deep neural networks or gradient boosting machines. This efficiency is especially useful when dealing with large numbers of base models in the ensemble, as it ensures that the meta-learner can be trained quickly and can make predictions in real-time.

\vspace{1em}

\noindent
The regularization capabilities of Logistic Regression are another advantage when used as a meta-learner. Regularization techniques such as L1 and L2 regularization can help prevent overfitting, which is a common issue when combining multiple models. By applying regularization, Logistic Regression ensures that the ensemble does not become too complex or overly tuned to the training data, improving the generalization performance on unseen data.

\vspace{1em}

\noindent
Moreover, Logistic Regression handles imbalanced data well, which is often a challenge in classification tasks. In ensemble settings, some base models might be more sensitive to the majority class, but Logistic Regression can adjust for class imbalances by applying class weights, ensuring that the ensemble model remains fair and does not favor the dominant class.

\vspace{1em}

\noindent
Another advantage of Logistic Regression is its ability to handle a large number of input features. In the case of an ensemble model, each base model's prediction can be treated as a feature, and Logistic Regression can effectively combine these features to make the final decision. This makes Logistic Regression versatile and adaptable when working with ensembles composed of diverse models, whether they are based on different algorithms or different data representations.

\vspace{1em}

\noindent
In summary, Logistic Regression is an ideal choice as a meta-learner in ensemble models because of its simplicity, interpretability, efficiency, and strong performance in combining probabilistic outputs. Its ability to apply regularization, handle imbalanced data, and process multiple features makes it a reliable and effective meta-learner that enhances the performance of the overall ensemble model.






\pagebreak

% ------------------------ Result and Analysis Ends -------------------------
